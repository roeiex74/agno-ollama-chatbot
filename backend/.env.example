# Environment (local|prod)
ENV=local

# Ollama configuration
# Use 1b model for better stability on limited resources
# Alternatives: llama3.2:1b (fastest), llama3.2:3b (balanced), llama3.3:70b (best quality)
OLLAMA_MODEL=llama3.2:1b
OLLAMA_HOST=http://localhost:11434
MODEL_TIMEOUT_S=60

# Database configuration
DATABASE_URL="postgresql+psycopg://user:password@localhost:5432/agno_chatbot"
MAX_HISTORY=20

# Server configuration
HOST=0.0.0.0
PORT=8000
